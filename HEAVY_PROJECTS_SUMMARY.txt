# Heavy Projects Queue Implementation - Summary

**Date**: 21 January 2026

## What Changed

### Problem
Heavy language projects (Rust, C++, Go, Java, C#) were timing out and blocking fast projects (Python, JavaScript) from processing.

### Solution
âœ… **Two-Queue System with Automatic Feeding**

1. **Main Queue** (ideas_log.json): 370 fast projects only
2. **Heavy Queue** (heavy_projects_queue.json): 304 heavy projects
3. **Auto-Feeding**: retry_manager feeds ONE heavy project when main queue < 50 items

---

## Implementation Details

### Files Modified

**cleanup_timeout_queue.py**
- âœ… Updated to create `heavy_projects_queue.json` instead of deleting projects
- Separates 304 heavy projects from 674 total
- Saves fast projects to `ideas_log.json`
- Shows breakdown by language (C++: 94, Go: 84, C#: 72, Java: 29, Rust: 25)

**retry_manager.py**
- âœ… Added `self.heavy_queue_file = Path('heavy_projects_queue.json')` to `__init__`
- âœ… Added `_feed_heavy_projects()` method (lines ~340-376)
  - Checks if main queue < 50 items
  - Takes ONE heavy project
  - Adds to ideas_log.json
  - Removes from heavy_projects_queue.json
  - Logs action to console
- âœ… Updated `run()` method to call `_feed_heavy_projects()` each cycle
- âœ… Updated startup banner to show "Heavy Projects: Run one-at-a-time when main queue < 50 items"

### New Files Created

**HEAVY_PROJECTS_SETUP.md**
- Complete documentation of setup
- Monitoring commands
- Troubleshooting guide
- Configuration instructions

---

## Current System State

```
âœ… Queues Separated:
   Fast:   370 projects (Python, JavaScript)
   Heavy:  304 projects (Rust, C++, Go, Java, C#)

âœ… Auto-Feeding Active:
   Threshold: Main queue < 50 items
   Batch: ONE heavy project at a time
   Frequency: Every 30 seconds (retry_manager cycle)

âœ… All Services Running:
   worker2:        PID 1353753
   retry_manager:  PID 1355797 (with heavy feeding logic)
   outline:        PID 210171
```

---

## How It Works in Practice

### Timeline Example

**Hour 1-2**: Fast projects process
```
ideas_log.json: 370 â†’ 360 â†’ 350 â†’ ... â†’ 55 items
heavy_projects_queue.json: 304 items (waiting)
```

**Hour 2**: Queue drops below 50
```
retry_manager detects: len(ideas) = 48
_feed_heavy_projects() triggers
Moves "RustyArt" to ideas_log.json
Log: "â¸ï¸  Fed 1 heavy project: RustyArt (RUST). Remaining: 303"
```

**Hour 3-12**: RustyArt processes (compilation may take 5-10 hours)
```
ideas_log.json: 48 â†’ 40 â†’ 30 â†’ 15 â†’ complete
worker processes RustyArt with 100x timeout multiplier
Long compilations don't block other projects
```

**Hour 12**: RustyArt completes, next heavy feeds
```
RustyArt moves to Desktop
ideas_log drops again: len(ideas) = 30
_feed_heavy_projects() triggers again
Moves "Text Adventure Game" (RUST) to ideas_log.json
Cycle repeats...
```

---

## Key Features

âœ… **No Projects Lost**
- 304 heavy projects backed up in separate queue
- Accessible via `heavy_projects_queue.json`
- Can restore anytime

âœ… **Predictable Resource Usage**
- Only ONE heavy project at a time
- No RAM spikes from parallel compilations
- Pi can handle one Rust/C++ compilation without crashing

âœ… **Fast Queue Never Starved**
- Fast projects always prioritized
- Heavy projects only feed when queue is small
- Learning database benefits from continuous Python/JS successes

âœ… **Smart Timeout Management**
- Heavy projects get 100x timeout multiplier
- Fast projects get 50x timeout multiplier
- No more false timeouts from slow compilations

âœ… **Automatic & Hands-Off**
- retry_manager handles everything
- No manual intervention needed
- Self-healing (feeds next heavy project when space available)

---

## Monitoring Commands

### Check queue sizes
```bash
echo "Fast queue:" && jq 'length' ideas_log.json
echo "Heavy queue:" && jq 'length' heavy_projects_queue.json
```

### Watch heavy projects being fed
```bash
tail -f retry_manager.log | grep "â¸ï¸"
```

### See what's processing
```bash
python3 monitor_queue.py --status
```

### Check heavy project details
```bash
# Next heavy project to run
jq '.[0] | {title, language}' heavy_projects_queue.json
```

---

## Future Adjustments

### If heavy projects feed too slowly:
Increase threshold from 50 to 100 in `retry_manager.py`:
```python
if len(ideas) > 100:  # More aggressive feeding
    return
```

### If heavy projects feed too fast:
Decrease threshold to 30 in `retry_manager.py`:
```python
if len(ideas) > 30:  # Less aggressive feeding
    return
```

### To pause heavy projects:
Rename the queue file:
```bash
mv heavy_projects_queue.json heavy_projects_queue.json.paused
```

### To re-enable everything at once:
```bash
cp ideas_log_backup_before_cleanup.json ideas_log.json
rm heavy_projects_queue.json
pkill worker2 && python3 -u worker2.py > worker2.log 2>&1 &
```

---

## Verification Checklist

- âœ… `cleanup_timeout_queue.py` creates `heavy_projects_queue.json`
- âœ… `heavy_projects_queue.json` contains 304 projects
- âœ… `ideas_log.json` contains 370 fast projects only
- âœ… `retry_manager.py` has `_feed_heavy_projects()` method
- âœ… `retry_manager.py` calls `_feed_heavy_projects()` in run loop
- âœ… Heavy projects only feed when queue < 50 items
- âœ… Exactly ONE heavy project fed per cycle
- âœ… retry_manager startup shows heavy project config
- âœ… All services running (worker2, retry_manager, outline)

---

## Success Metrics

ðŸŽ¯ **What Success Looks Like:**
1. Fast queue depletes predictably (no more timeouts)
2. Heavy projects gradually move from queue to Desktop
3. Learning database captures fixes from both queues
4. System remains stable under old Pi hardware
5. retry_manager logs show periodic "â¸ï¸ Fed 1 heavy project..." messages

---

## Questions?

See `HEAVY_PROJECTS_SETUP.md` for detailed documentation, monitoring, and troubleshooting.
