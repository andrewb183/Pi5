{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Database Effectiveness Analysis\n",
    "\n",
    "This notebook tracks the effectiveness of the learning fix database in `escalating_retry_system.py`:\n",
    "- Fix reuse rates over time\n",
    "- Learning efficiency metrics\n",
    "- Database growth patterns\n",
    "- Most reusable fix patterns\n",
    "- ROI on learned fixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Fix Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the learning fix database\n",
    "db_path = Path('../implementation_outputs/fix_database.json')\n",
    "\n",
    "fix_db = None\n",
    "if db_path.exists():\n",
    "    with open(db_path) as f:\n",
    "        fix_db = json.load(f)\n",
    "    print(\"âœ… Fix database loaded successfully\")\n",
    "else:\n",
    "    print(\"âš ï¸ Fix database not found - creating empty structure\")\n",
    "    fix_db = {\n",
    "        'metadata': {\n",
    "            'total_fixes': 0,\n",
    "            'reuse_rate': 0.0,\n",
    "            'learning_efficiency': 0.0\n",
    "        },\n",
    "        'error_signatures': {}\n",
    "    }\n",
    "\n",
    "metadata = fix_db.get('metadata', {})\n",
    "error_signatures = fix_db.get('error_signatures', {})\n",
    "\n",
    "print(f\"\\nðŸ“Š Database Stats:\")\n",
    "print(f\"  Total fixes learned: {metadata.get('total_fixes', 0)}\")\n",
    "print(f\"  Unique error signatures: {len(error_signatures)}\")\n",
    "print(f\"  Reuse rate: {metadata.get('reuse_rate', 0):.2%}\")\n",
    "print(f\"  Learning efficiency: {metadata.get('learning_efficiency', 0):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database Growth Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze growth of database\n",
    "fix_timeline = []\n",
    "\n",
    "for error_sig, fixes in error_signatures.items():\n",
    "    for fix in fixes:\n",
    "        if 'learned_at' in fix:\n",
    "            try:\n",
    "                dt = datetime.fromisoformat(fix['learned_at'].replace('Z', '+00:00'))\n",
    "                fix_timeline.append({\n",
    "                    'timestamp': dt,\n",
    "                    'error_type': fix.get('error_category', 'Unknown'),\n",
    "                    'reuse_count': fix.get('reuse_count', 0),\n",
    "                    'success_rate': fix.get('success_rate', 0.0)\n",
    "                })\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "if fix_timeline:\n",
    "    # Sort by timestamp\n",
    "    fix_timeline.sort(key=lambda x: x['timestamp'])\n",
    "    \n",
    "    # Cumulative fixes learned\n",
    "    cumulative_fixes = list(range(1, len(fix_timeline) + 1))\n",
    "    timestamps = [f['timestamp'] for f in fix_timeline]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 5))\n",
    "    ax.plot(timestamps, cumulative_fixes, linewidth=2, marker='o', markersize=4, color='green')\n",
    "    ax.fill_between(timestamps, cumulative_fixes, alpha=0.3, color='green')\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_ylabel('Cumulative Fixes Learned')\n",
    "    ax.set_title('Learning Database Growth Over Time')\n",
    "    ax.grid(alpha=0.3)\n",
    "    \n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nðŸ“ˆ Growth Analysis:\")\n",
    "    print(f\"  First fix learned: {timestamps[0].strftime('%Y-%m-%d %H:%M')}\")\n",
    "    print(f\"  Latest fix learned: {timestamps[-1].strftime('%Y-%m-%d %H:%M')}\")\n",
    "    print(f\"  Total fixes in database: {len(fix_timeline)}\")\n",
    "    \n",
    "    # Calculate learning rate\n",
    "    time_span = (timestamps[-1] - timestamps[0]).total_seconds() / 3600  # hours\n",
    "    if time_span > 0:\n",
    "        learning_rate = len(fix_timeline) / time_span\n",
    "        print(f\"  Learning rate: {learning_rate:.2f} fixes/hour\")\n",
    "else:\n",
    "    print(\"No timeline data available yet - database is empty\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix Reuse Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze which fixes are most reused\n",
    "reuse_data = []\n",
    "\n",
    "for error_sig, fixes in error_signatures.items():\n",
    "    for i, fix in enumerate(fixes):\n",
    "        reuse_count = fix.get('reuse_count', 0)\n",
    "        success_rate = fix.get('success_rate', 0.0)\n",
    "        error_type = fix.get('error_category', 'Unknown')\n",
    "        \n",
    "        reuse_data.append({\n",
    "            'error_signature': error_sig[:50] + '...' if len(error_sig) > 50 else error_sig,\n",
    "            'fix_index': i,\n",
    "            'reuse_count': reuse_count,\n",
    "            'success_rate': success_rate,\n",
    "            'error_type': error_type,\n",
    "            'roi': reuse_count * success_rate  # Simple ROI metric\n",
    "        })\n",
    "\n",
    "if reuse_data:\n",
    "    # Sort by reuse count\n",
    "    reuse_data.sort(key=lambda x: x['reuse_count'], reverse=True)\n",
    "    \n",
    "    # Plot top 10 most reused fixes\n",
    "    top_10 = reuse_data[:10]\n",
    "    \n",
    "    if top_10:\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "        \n",
    "        # Reuse counts\n",
    "        labels = [f\"Fix {i+1}\" for i in range(len(top_10))]\n",
    "        counts = [f['reuse_count'] for f in top_10]\n",
    "        ax1.barh(labels, counts, color='teal')\n",
    "        ax1.set_xlabel('Reuse Count')\n",
    "        ax1.set_title('Top 10 Most Reused Fixes')\n",
    "        ax1.invert_yaxis()\n",
    "        \n",
    "        # Success rates\n",
    "        success_rates = [f['success_rate'] * 100 for f in top_10]\n",
    "        ax2.barh(labels, success_rates, color='orange')\n",
    "        ax2.set_xlabel('Success Rate (%)')\n",
    "        ax2.set_title('Success Rate of Top Reused Fixes')\n",
    "        ax2.invert_yaxis()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    print(\"\\nðŸ† Most Effective Fixes:\")\n",
    "    # Sort by ROI\n",
    "    reuse_data.sort(key=lambda x: x['roi'], reverse=True)\n",
    "    for i, fix in enumerate(reuse_data[:5], 1):\n",
    "        print(f\"\\n{i}. Error Type: {fix['error_type']}\")\n",
    "        print(f\"   Reuse Count: {fix['reuse_count']}\")\n",
    "        print(f\"   Success Rate: {fix['success_rate']:.1%}\")\n",
    "        print(f\"   ROI Score: {fix['roi']:.2f}\")\n",
    "    \n",
    "    # Calculate overall reuse statistics\n",
    "    total_reuses = sum(f['reuse_count'] for f in reuse_data)\n",
    "    avg_reuse = total_reuses / len(reuse_data) if reuse_data else 0\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Reuse Statistics:\")\n",
    "    print(f\"  Total fix applications: {total_reuses}\")\n",
    "    print(f\"  Average reuse per fix: {avg_reuse:.2f}\")\n",
    "    print(f\"  Fixes never reused: {sum(1 for f in reuse_data if f['reuse_count'] == 0)}\")\n",
    "    print(f\"  Fixes reused 5+ times: {sum(1 for f in reuse_data if f['reuse_count'] >= 5)}\")\n",
    "else:\n",
    "    print(\"No reuse data available - database hasn't been utilized yet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Type Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze coverage of different error types\n",
    "error_type_coverage = Counter()\n",
    "\n",
    "for error_sig, fixes in error_signatures.items():\n",
    "    for fix in fixes:\n",
    "        error_type = fix.get('error_category', 'Unknown')\n",
    "        error_type_coverage[error_type] += 1\n",
    "\n",
    "if error_type_coverage:\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    types = list(error_type_coverage.keys())\n",
    "    counts = list(error_type_coverage.values())\n",
    "    \n",
    "    colors = plt.cm.Set3(range(len(types)))\n",
    "    ax.pie(counts, labels=types, autopct='%1.1f%%', colors=colors, startangle=90)\n",
    "    ax.set_title('Fix Coverage by Error Type')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nðŸ“Š Coverage by Error Type:\")\n",
    "    for error_type, count in error_type_coverage.most_common():\n",
    "        print(f\"  {error_type:20s}: {count:3d} fixes available\")\n",
    "else:\n",
    "    print(\"No error type data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Efficiency Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate advanced efficiency metrics\n",
    "if reuse_data:\n",
    "    # Time saved calculation (assume 5 minutes per manual fix)\n",
    "    total_reuses = sum(f['reuse_count'] for f in reuse_data)\n",
    "    time_saved_minutes = total_reuses * 5\n",
    "    time_saved_hours = time_saved_minutes / 60\n",
    "    \n",
    "    # Success-weighted efficiency\n",
    "    successful_reuses = sum(f['reuse_count'] * f['success_rate'] for f in reuse_data)\n",
    "    \n",
    "    # Database utilization\n",
    "    utilized_fixes = sum(1 for f in reuse_data if f['reuse_count'] > 0)\n",
    "    utilization_rate = utilized_fixes / len(reuse_data) if reuse_data else 0\n",
    "    \n",
    "    print(\"\\nâš¡ Efficiency Metrics:\")\n",
    "    print(f\"  Total fix applications: {total_reuses}\")\n",
    "    print(f\"  Successful applications: {successful_reuses:.1f}\")\n",
    "    print(f\"  Estimated time saved: {time_saved_hours:.1f} hours\")\n",
    "    print(f\"  Database utilization: {utilization_rate:.1%}\")\n",
    "    print(f\"  Average success rate: {(sum(f['success_rate'] for f in reuse_data) / len(reuse_data)):.1%}\")\n",
    "    \n",
    "    # ROI visualization\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    \n",
    "    # Plot ROI distribution\n",
    "    roi_values = [f['roi'] for f in reuse_data if f['roi'] > 0]\n",
    "    if roi_values:\n",
    "        ax.hist(roi_values, bins=20, color='green', alpha=0.7, edgecolor='black')\n",
    "        ax.set_xlabel('ROI Score (Reuse Count Ã— Success Rate)')\n",
    "        ax.set_ylabel('Number of Fixes')\n",
    "        ax.set_title('Distribution of Fix ROI')\n",
    "        ax.axvline(sum(roi_values) / len(roi_values), color='red', linestyle='--', \n",
    "                   label=f'Average ROI: {sum(roi_values) / len(roi_values):.2f}')\n",
    "        ax.legend()\n",
    "        ax.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"Not enough data for efficiency metrics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nðŸŽ¯ DATABASE OPTIMIZATION RECOMMENDATIONS:\\n\")\n",
    "\n",
    "if reuse_data:\n",
    "    # Find underutilized fixes\n",
    "    never_used = sum(1 for f in reuse_data if f['reuse_count'] == 0)\n",
    "    if never_used > 0:\n",
    "        print(f\"1. {never_used} fixes have never been reused - consider pruning or improving signatures\")\n",
    "    \n",
    "    # Find low success rate fixes\n",
    "    low_success = [f for f in reuse_data if f['success_rate'] < 0.5 and f['reuse_count'] > 0]\n",
    "    if low_success:\n",
    "        print(f\"2. {len(low_success)} fixes have <50% success rate - review and improve these\")\n",
    "    \n",
    "    # Coverage gaps\n",
    "    if error_type_coverage:\n",
    "        min_coverage = min(error_type_coverage.values())\n",
    "        min_type = [k for k, v in error_type_coverage.items() if v == min_coverage][0]\n",
    "        print(f\"3. '{min_type}' has lowest coverage ({min_coverage} fixes) - add more patterns\")\n",
    "    \n",
    "    # High performers\n",
    "    high_roi = [f for f in reuse_data if f['roi'] > 10]\n",
    "    if high_roi:\n",
    "        print(f\"4. {len(high_roi)} fixes have high ROI - document and replicate their patterns\")\n",
    "    \n",
    "    print(\"\\n5. Continue learning - database is actively improving the system\")\n",
    "    print(\"6. Monitor reuse rate trends to validate learning effectiveness\")\n",
    "else:\n",
    "    print(\"1. Database is empty - start running retry system to build knowledge\")\n",
    "    print(\"2. Ensure escalating_retry_system.py is properly configured\")\n",
    "    print(\"3. Allow system to learn from at least 10 successful fixes before analysis\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
