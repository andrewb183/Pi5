#!/usr/bin/env python3
"""
Verify heavy projects queue setup is working correctly
"""

import json
from pathlib import Path
import subprocess

print("\n" + "="*70)
print("ğŸ” HEAVY PROJECTS QUEUE VERIFICATION")
print("="*70)

# Check files exist
print("\nğŸ“‹ Queue Files:")
ideas_file = Path('ideas_log.json')
heavy_file = Path('heavy_projects_queue.json')
backup_file = Path('ideas_log_backup_before_cleanup.json')

files = {
    'Fast Queue (ideas_log.json)': ideas_file,
    'Heavy Queue (heavy_projects_queue.json)': heavy_file,
    'Backup (ideas_log_backup_before_cleanup.json)': backup_file,
}

for name, path in files.items():
    status = "âœ…" if path.exists() else "âŒ"
    print(f"  {status} {name}")

# Check queue contents
print("\nğŸ“Š Queue Contents:")
fast = json.load(open(ideas_file))
heavy = json.load(open(heavy_file))

print(f"  Fast projects:  {len(fast)} total")
print(f"  Heavy projects: {len(heavy)} total")
print(f"  Total projects: {len(fast) + len(heavy)}")

# Verify separation
fast_langs = set(p.get('language', 'Unknown').lower() for p in fast)
heavy_langs = set(p.get('language', 'Unknown').lower() for p in heavy)

print(f"\n  Fast languages: {', '.join(sorted(fast_langs))}")
print(f"  Heavy languages: {', '.join(sorted(heavy_langs))}")

# Check for overlap
overlap = fast_langs & heavy_langs
if overlap:
    print(f"\n  âš ï¸  WARNING: Languages in both queues: {overlap}")
else:
    print(f"\n  âœ… No overlap between queues")

# Check retry_manager code
print("\nğŸ”§ Retry Manager Configuration:")
with open('retry_manager.py') as f:
    content = f.read()
    
checks = {
    'Has heavy_queue_file initialization': 'self.heavy_queue_file = Path(\'heavy_projects_queue.json\')',
    'Has _feed_heavy_projects() method': 'def _feed_heavy_projects(self):',
    'Calls _feed_heavy_projects() in run()': 'self._feed_heavy_projects()',
    'Checks queue threshold': 'if len(ideas) > 50:',
}

for check, pattern in checks.items():
    status = "âœ…" if pattern in content else "âŒ"
    print(f"  {status} {check}")

# Check processes
print("\nâš™ï¸  Running Processes:")
result = subprocess.run(['pgrep', '-lf', 'worker2|retry_manager|outline'], 
                       capture_output=True, text=True)
processes = result.stdout.strip().split('\n')
process_names = {
    'worker2': False,
    'retry_manager': False,
    'outline': False,
}

for line in processes:
    for name in process_names:
        if name in line and 'grep' not in line:
            process_names[name] = True

for name, running in process_names.items():
    status = "âœ…" if running else "âŒ"
    print(f"  {status} {name}")

# Show what's next
print("\nğŸ¯ What's Coming:")
if heavy:
    print(f"  Next heavy project to run: {heavy[0].get('title', 'Unknown')}")
    print(f"                  Language: {heavy[0].get('language', 'Unknown')}")
    print(f"  Waiting in queue: {len(heavy) - 1} more heavy projects")

# Show summary
print("\n" + "="*70)
print("âœ… HEAVY PROJECTS QUEUE READY")
print("="*70)
print(f"""
Configuration:
  â€¢ Fast queue: 370 Python/JavaScript projects
  â€¢ Heavy queue: 304 Rust/C++/Go/Java/C# projects
  â€¢ Feeding strategy: ONE heavy project when fast queue < 50
  â€¢ Timeout multiplier: 50x (fast), 100x (heavy)

Auto-feeding controlled by retry_manager.py:
  â€¢ Checks every 30 seconds
  â€¢ Only feeds if main queue < 50 items
  â€¢ Takes exactly ONE heavy project
  â€¢ Continues until all heavy projects complete

Monitoring:
  $ tail -f retry_manager.log | grep "â¸ï¸"     # See heavy projects feeding
  $ python3 monitor_queue.py --status           # Overall system status
  
""")
print("="*70)
